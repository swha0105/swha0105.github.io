---
layout: post
title:  "[ML Posts] Mixed Membership Model"
subtitle:   "Post"
categories: ml_dl
tags: ml_post
comments: False
---


### 들어가기전
내가 보는 Modeling 논문에서 거의 모든 논문이 Mixed Membership Model(MMM)을 사전지식으로 요구한다.  이것도 Mixtured Model의 확장판이라고만 알고있지 자세히 알지 못한다.  
꼭 알아야되는 지식으로 판단되고, 텍스트북에 안나와있지만 이 [자료]()를 참고하여 정리한다

# Introduction

- Population에서 있는 Individual은 multiple subpopulation에 속할 수 있다는 아이디어로 부터 시작한다
  - 뉴스기사는 여러 category에 속할 수 있다.
  - 환자는 여러 질병에 동시에 걸릴 수 있다
  - 학생들은 수학문제를 푸는데 있어 여러 접근방법을 사용할 수 있다

- 이 아이디어를 probability model 발전한건 Woodbury et al (1978) 부터 였고 이후, Pritchard et al (2000), Blei et al (2003), Erosheva(2002, 2004) 을 통해 General Mixed Membership framework가 정립되었다.

- 특히, Erosheva(2002, 2004)에서는 MMM이 finite mixture model의 표현과 일치한다는것을 증명하였다. 


<br/>

# Mixed Membership Model

- 역사적으로 많은 MMM들이 개발되었지만 현재, Blei et al(2003) (LDA 논문)와 Erosheva(2002, 2004) 방법이 통용적으로 사용되고 있다. 

## The Generative Process
### 정의
- Population은 K 개의 `profile`로 구성된다 (k = 1,2,3 ... K)
- `Individual`은 (i = 1,2,3 ... N)은 profile분포에서 각각 다른 degree로 속한다
- 각각의 individual은 profiles에 얼마나 속하는지 (degree) 나타내는 `Membership vector` ($$\theta_{i} = (\theta_{i1},\theta_{i2} ... \theta_{iK})$$)를 가지고 있다
- Observed variable ($$X_{j}, j =1,2, ... J$$)은 각 profile에 다른 probability distribution을 가진다
  - $$ X_{ijr}$$: i번째 individual에있는 j번쨰 oberseved variable을 복재한것 ($$ r = 1,2,3 ... R_{ij}$$)
- Indicator vector $$Z_{ijr}$$은 profile i가 j번째 variable을 복제한 r에 대해 따르는지 알려주는 벡터
  - Membership vector는 individual이 profiles에 속할 degree을 나타내줌. 따라서 $$Z_{ijr} \sim Multinomial(\theta_{i})$$
- in LDA example
  - **Population**: Corpus of document
  - **Profile**: Topics in document
  - **Individual**: Document
  - **Observed Variable**: Word
  - **Membership vector**: i번째 document에 대한 topic분포
  - **Indicator vector**: i번째 document의 r번째 word가 어떤 topic에서 왔는지 알려주는 벡터


- 각 variable (j = 1,2, ... ,J)에 대해 
  - 각 replication (r = 1,2, ... , $$R_{ij}$$)에 대해
      1. $$Z_{ijr} \sim Multinomial(\theta_{i})$$ 를 구한 뒤
      2. $$X_{ujr} \sim F_{Z_{ijf},j}(x_{j})$$를 계산한다
      > F: cumulative distribution function of $$X_{j}$$ given $$Z_{ijf}$$ 

<br/>

## General Mixed Membership Model

- General Mixed Membership Model(MMM) 은 generative process에서 나온 가정들을 general model로 설명한다. `population level`, `subject level`, `sampling scheme`, `latent variable level`로 구성되고 각각의 assumption이 존재한다.

**1. Population level assumption**
- population에 K개의 다른 `profile`이 존재한다
- profile은 obseved variables에 대한 각기 다른 probability distribution ($$F_{kj}$$)가 존재한다. 

**2. Subject level assumption**

$$ F(x_{j} \lvert \theta_{i}) = \sum_{k=1}^{K} P(Z_{ijrk} = 1 \lvert \theta_{i}) F(x_{j} \lvert Z_{ijrk} = 1) = \sum_{k=1}^{K} \theta_{ik} F_{kj} (x_{j})$$

- 위 수식은 Membership vector ($$\theta$$)가 주어졌을때, $$x_{j}$$의 확률을 의미한다.
- $$x_{j, j \in (1,2, .. J)}$$는 $$\theta_{i}$$가 주어졌을때 서로 독립이다 (`Conditionally Independence`) 위의 가정을 바탕으로 수식을 다시 쓰게 되면 아래와 같다.

$$ F(x \lvert \theta_{i}) = \Pi_{j=1}^{J} \sum_{k=1}^{K} \theta_{ik} F_{kj}(x_{j})$$

**3. Sampling scheme level assumption**

$$ F(x \lvert \theta_{i}) = \Pi_{j=1}^{J} \Pi_{r=1}^{R_{ij}} \sum_{k=1}^{K} \theta_{ik} F_{kj}(x_{j})$$

- subject level에서 나온 수식을 (Observed variable -> Individual level)로 확장 
- $$F_{kj}$$는 population level에서 정해졌기 때문에, component ($$\theta$$, membership vector)의 구성은 같다. 다만 component의 값 ($$\theta_{i}$$)값은 각각 다르다
- component를 random이라 가정하고 integration한 수식은 아래와 같다.

$$ F(x) = \int \Pi_{j}^{J} \Pi_{r=1}^{R_{ij}} \sum_{k=1}^{K} \theta_{ik}F_{kj}(x_{j}) d D(\theta)$$

4. Latent variable level assumption
에 대한 것은 이 챕터에서 생략되어있다. estimation 챕터에 자세히 설명한다고 한다.

### 시간되면 뒤에 챕터도 정리할 계획...

<script>
MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
</script>

<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
